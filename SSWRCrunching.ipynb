{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import itertools\n",
    "import torch, os\n",
    "import numpy as np\n",
    "from radbm.metrics.sswr import HaltingCounterSSWR\n",
    "from radbm.search.mbsds import HashingMultiBernoulliSDS\n",
    "from radbm.search.elba import Fbeta, MIHash, HashNet\n",
    "state_dir = #The path where the experiments took place, it is the same state_dir as in run_<type>.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#util function\n",
    "def avg_if_enough(values, minimum_for_avg):\n",
    "    values = np.array(values)\n",
    "    notnan = ~np.isnan(values)\n",
    "    return values[notnan].mean() if notnan.sum() >= minimum_for_avg else np.inf\n",
    "\n",
    "def batch_avg_if_enough(values, minimum_for_avg):\n",
    "    return np.array([avg_if_enough(v, minimum_for_avg) for v in values])\n",
    "\n",
    "def nparray_to_latextable(array, columns, rows):\n",
    "    #this produce the latex code (don't try to read it)\n",
    "    return ' \\\\\\\\\\n'.join([' & '.join(columns)] + [' & '.join([name] + ['{:.4f}'.format(v) for v in row])\n",
    "                                                      for name, row in zip(rows, array.round(4))\n",
    "                                                  ]\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = [\n",
    "    'fbeta',\n",
    "    'mihash',\n",
    "    'hashnet',\n",
    "    'shared_fbeta',\n",
    "    'shared_mihash',\n",
    "    'shared_hashnet',\n",
    "]\n",
    "models = [m+str(i) for m in model_types for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models & HRS & HMBS & HRS-Halt% & HMBS-Halt% \\\\\n",
      "fbeta & 0.3798 & 0.0169 & 22.5120 & 0.2040 \\\\\n",
      "mihash & 1.3559 & 1.8907 & 92.7176 & 92.1903 \\\\\n",
      "hashnet & 1.4162 & 2.0001 & 100.0000 & 100.0000 \\\\\n",
      "shared_fbeta & 0.1636 & 0.0035 & 8.6440 & 0.0000 \\\\\n",
      "shared_mihash & 0.2119 & 0.0083 & 11.8080 & 0.0960 \\\\\n",
      "shared_hashnet & 0.2536 & 0.2828 & 16.1360 & 12.8786\n"
     ]
    }
   ],
   "source": [
    "#Experiment 1\n",
    "path = os.path.join(state_dir, 'current/{}')\n",
    "results = {\n",
    "    name: torch.load(path.format(name), map_location=torch.device('cpu'))['results']\n",
    "    for name in models\n",
    "}\n",
    "\n",
    "sswrs_halts = np.zeros((6,4))\n",
    "for n, t in enumerate(model_types):\n",
    "    hr_sswrs = np.zeros((5,5))\n",
    "    mb_sswrs = np.zeros((5,5))\n",
    "    hr_halts = np.zeros((5,5))\n",
    "    mb_halts = np.zeros((5,5))\n",
    "    for i in range(5):\n",
    "        hr_row = batch_avg_if_enough(results[t+str(i)]['valid_2081hr_sswrs'], 2)\n",
    "        mb_row = batch_avg_if_enough(results[t+str(i)]['valid_5001mb_sswrs'], 2)\n",
    "        hr_index = hr_row.argsort()[:5]\n",
    "        mb_index = mb_row.argsort()[:5]\n",
    "        hr_sswrs[i] = hr_row[hr_index]\n",
    "        mb_sswrs[i] = mb_row[mb_index]\n",
    "        hr_halts[i] = 100*batch_avg_if_enough(results[t+str(i)]['valid_2081hr_halts'], 2)[hr_index]\n",
    "        mb_halts[i] = 100*batch_avg_if_enough(results[t+str(i)]['valid_5001mb_halts'], 2)[mb_index]\n",
    "    sswrs_halts[n, 0] = hr_sswrs.mean()\n",
    "    sswrs_halts[n, 1] = mb_sswrs.mean()\n",
    "    sswrs_halts[n, 2] = hr_halts.mean()\n",
    "    sswrs_halts[n, 3] = mb_halts.mean()\n",
    "print(nparray_to_latextable(sswrs_halts, ['Models','HRS','HMBS','HRS-Halt%','HMBS-Halt%'], model_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fbeta0_mb0 crunched\n",
      "fbeta0_mb1 crunched\n",
      "fbeta0_mb2 crunched\n",
      "fbeta0_mb3 crunched\n",
      "fbeta0_mb4 crunched\n",
      "fbeta1_mb0 crunched\n",
      "fbeta1_mb1 crunched\n",
      "fbeta1_mb2 crunched\n",
      "fbeta1_mb3 crunched\n",
      "fbeta1_mb4 crunched\n",
      "fbeta2_mb0 crunched\n",
      "fbeta2_mb1 crunched\n",
      "fbeta2_mb2 crunched\n",
      "fbeta2_mb3 crunched\n",
      "fbeta2_mb4 crunched\n",
      "fbeta3_mb0 crunched\n",
      "fbeta3_mb1 crunched\n",
      "fbeta3_mb2 crunched\n",
      "fbeta3_mb3 crunched\n",
      "fbeta3_mb4 crunched\n",
      "fbeta4_mb0 crunched\n",
      "fbeta4_mb1 crunched\n",
      "fbeta4_mb2 crunched\n",
      "fbeta4_mb3 crunched\n",
      "fbeta4_mb4 crunched\n",
      "shared_fbeta0_mb0 crunched\n",
      "shared_fbeta0_mb1 crunched\n",
      "shared_fbeta0_mb2 crunched\n",
      "shared_fbeta0_mb3 crunched\n",
      "shared_fbeta0_mb4 crunched\n",
      "shared_fbeta1_mb0 crunched\n",
      "shared_fbeta1_mb1 crunched\n",
      "shared_fbeta1_mb2 crunched\n",
      "shared_fbeta1_mb3 crunched\n",
      "shared_fbeta1_mb4 crunched\n",
      "shared_fbeta2_mb0 crunched\n",
      "shared_fbeta2_mb1 crunched\n",
      "shared_fbeta2_mb2 crunched\n",
      "shared_fbeta2_mb3 crunched\n",
      "shared_fbeta2_mb4 crunched\n",
      "shared_fbeta3_mb0 crunched\n",
      "shared_fbeta3_mb1 crunched\n",
      "shared_fbeta3_mb2 crunched\n",
      "shared_fbeta3_mb3 crunched\n",
      "shared_fbeta3_mb4 crunched\n",
      "shared_fbeta4_mb0 crunched\n",
      "shared_fbeta4_mb1 crunched\n",
      "shared_fbeta4_mb2 crunched\n",
      "shared_fbeta4_mb3 crunched\n",
      "shared_fbeta4_mb4 crunched\n",
      "shared_mihash0_mb0 crunched\n",
      "shared_mihash0_mb1 crunched\n",
      "shared_mihash0_mb2 crunched\n",
      "shared_mihash0_mb3 crunched\n",
      "shared_mihash0_mb4 crunched\n",
      "shared_mihash1_mb0 crunched\n",
      "shared_mihash1_mb1 crunched\n",
      "shared_mihash1_mb2 crunched\n",
      "shared_mihash1_mb3 crunched\n",
      "shared_mihash1_mb4 crunched\n",
      "shared_mihash2_mb0 crunched\n",
      "shared_mihash2_mb1 crunched\n",
      "shared_mihash2_mb2 crunched\n",
      "shared_mihash2_mb3 crunched\n",
      "shared_mihash2_mb4 crunched\n",
      "shared_mihash3_mb0 crunched\n",
      "shared_mihash3_mb1 crunched\n",
      "shared_mihash3_mb2 crunched\n",
      "shared_mihash3_mb3 crunched\n",
      "shared_mihash3_mb4 crunched\n",
      "shared_mihash4_mb0 crunched\n",
      "shared_mihash4_mb1 crunched\n",
      "shared_mihash4_mb2 crunched\n",
      "shared_mihash4_mb3 crunched\n",
      "shared_mihash4_mb4 crunched\n",
      "shared_hashnet0_mb0 crunched\n",
      "shared_hashnet0_mb1 crunched\n",
      "shared_hashnet0_mb2 crunched\n",
      "shared_hashnet0_mb3 crunched\n"
     ]
    }
   ],
   "source": [
    "#Experiment 2\n",
    "max_halt = 10000\n",
    "allowed_types = [\n",
    "    'fbeta',\n",
    "    'shared_fbeta',\n",
    "    'shared_mihash',\n",
    "    'shared_hashnet',\n",
    "]\n",
    "\n",
    "with open('common.py', 'r') as f:\n",
    "    exec(f.read())\n",
    "\n",
    "def evaluate(model, documents, queries, relevances, max_halt, batch_size=100):\n",
    "    #return sswrs, halts\n",
    "    #sswrs.shape == halts.shape == (#table_setting=5, max_halt)\n",
    "    model.eval()\n",
    "    N, M = len(documents), len(queries)\n",
    "    with torch.no_grad():\n",
    "        dlogits = torch.cat(batch_call(model.fd, documents, batch_size), dim=0)\n",
    "        qlogits = torch.cat(batch_call(model.fq, queries, batch_size), dim=0)\n",
    "        dls_pairs = model._log_sigmoid_pairs(dlogits)\n",
    "        qls_pairs = model._log_sigmoid_pairs(qlogits)\n",
    "    sswrs = np.zeros((5, M, max_halt+1))\n",
    "    halts = np.zeros((5, M, max_halt+1))\n",
    "    for i, ntables in enumerate([1,2,4,8,16]):\n",
    "        struct = HashingMultiBernoulliSDS(ntables, 1)\n",
    "        struct.batch_insert(dls_pairs, range(N))\n",
    "        gens = struct.batch_itersearch(qls_pairs, yield_empty=True)\n",
    "        for j, (gen, rel) in enumerate(zip(gens, relevances)):\n",
    "            sswr, halt = HaltingCounterSSWR(rel, gen, N, max_halt)\n",
    "            sswrs[i, j] = sswr\n",
    "            halts[i, j] = halt\n",
    "    return sswrs.mean(axis=1), sswrs.std(axis=1), halts.mean(axis=1), halts.std(axis=1)\n",
    "        \n",
    "batchs = np.zeros((len(allowed_types), 5, 5), dtype=np.int64)\n",
    "sswrs = np.zeros((len(allowed_types), 5, max_halt+1))\n",
    "sswrs_std = np.zeros((len(allowed_types), 5, max_halt+1))\n",
    "halts = np.zeros((len(allowed_types), 5, max_halt+1))\n",
    "halts_std = np.zeros((len(allowed_types), 5, max_halt+1))\n",
    "#model_name = '{}_hr{}'\n",
    "#path = os.path.join(state_dir, 'hr', model_name)\n",
    "model_name = '{}_mb{}' #hashtag this and the next lines and unhashtag the two lines above to crunch w.r.t. hamming radius\n",
    "path = os.path.join(state_dir, 'mb', model_name)\n",
    "for n, t in enumerate(allowed_types):\n",
    "    fq = MNISTResNet(64)\n",
    "    fd = fq if t.startswith('shared') else MNISTResNet(64)\n",
    "    if t.endswith('fbeta'):\n",
    "        model = Fbeta(fq, fd, None, -np.log(10000))\n",
    "    elif t.endswith('mihash'):\n",
    "        model = MIHash(fq, fd, None, 64, 1/8)\n",
    "    elif t.endswith('hashnet'):\n",
    "        model = HashNet(fq, fd, None, 1/2)\n",
    "    else: raise ValueError()\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    t_sswrs = np.zeros((5, 5, 5, max_halt+1))\n",
    "    t_sswrs_std = np.zeros((5, 5, 5, max_halt+1))\n",
    "    t_halts = np.zeros((5, 5, 5, max_halt+1))\n",
    "    t_halts_std = np.zeros((5, 5, 5, max_halt+1))\n",
    "    for i, j in itertools.product(range(5), range(5)):\n",
    "        state = torch.load(path.format(t+str(i), j))\n",
    "        batchs[n, i, j] = state.pop('nbatch')\n",
    "        model.load_state_dict(state)\n",
    "        t_sswrs[i, j], t_sswrs_std[i, j], t_halts[i, j], t_halts_std[i, j] = evaluate(\n",
    "            model, valid_d, valid_q, relevances, max_halt)\n",
    "        print('{} crunched'.format(model_name.format(t+str(i), j)))\n",
    "    sswrs[n] = t_sswrs.mean(axis=(0,1))\n",
    "    sswrs_std[n] = t_sswrs_std.mean(axis=(0,1))\n",
    "    halts[n] = t_halts.mean(axis=(0,1))\n",
    "    halts_std[n] = t_halts_std.mean(axis=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment to save\n",
    "\n",
    "#import pickle\n",
    "#with open('mbcrunch.pkl', 'wb') as f:\n",
    "#    data = (batchs, sswrs, sswrs_std, halts, halts_std)\n",
    "#    pickle.dump(data, f, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
